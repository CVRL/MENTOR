{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MENTOR training\n",
    "\n",
    "Note this notebook does not reflect the experiments performed in the paper in its entirety as efforts were made to keep annonymity in the review process.\n",
    "\n",
    "The authors would like to thank [Segmentation Models](https://github.com/qubvel/segmentation_models.pytorch) repo for examples and guidance during the creation of this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_dir = \"/train\"\n",
    "y_train_dir = \"/trainannot\"\n",
    "\n",
    "x_valid_dir = \"/val\"\n",
    "y_valid_dir = \"/valannot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(BaseDataset):\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = Image.open(self.images_fps[i]).convert(\"RGB\")\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize([256, 256]),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        image = transform(image)\n",
    "        \n",
    "        mask = Image.open(self.masks_fps[i].replace(\".jpg\", \".png\")).convert(\"RGB\")\n",
    "        map_transform = transforms.Compose([\n",
    "            transforms.Resize([256, 256]),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        mask = map_transform(mask)\n",
    "        mask = mask - torch.min(mask)\n",
    "        mask = mask / torch.max(mask)\n",
    "                                \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image)\n",
    "            image = sample['image']\n",
    "\n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet50' # Change encoder here\n",
    "ENCODER_WEIGHTS = 'imagenet' # 'imagenet'\n",
    "ACTIVATION = None\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "# we also experimented with smp.Unet\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=1,\n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_loss = nn.MSELoss()\n",
    "\n",
    "solver = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=None,\n",
    "    preprocessing=None,\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    augmentation=None,\n",
    "    preprocessing=None,\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=1, pin_memory=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=True, num_workers=1, pin_memory=True, drop_last=True)\n",
    "\n",
    "d = {'train': train_loader, 'test': valid_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "log = {'iterations':[], 'epoch':[], 'validation':[], 'train_acc':[], 'val_acc':[]}\n",
    "log_path = \"./mentor_weights\"\n",
    "train_loss=[]\n",
    "test_loss=[]\n",
    "bestAccuracy = 1\n",
    "bestEpoch=0\n",
    "train_step = 0\n",
    "val_step = 0\n",
    "for epoch in range(11): # training for only 10 epochs\n",
    "    for phase in ['train', 'test']:\n",
    "        train = (phase=='train')\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "        tloss = 0.\n",
    "        metric = 0.\n",
    "        tot = 0\n",
    "        c = 0\n",
    "        testPredScore = []\n",
    "        testTrueLabel = []\n",
    "        imgNames=[]\n",
    "        with torch.set_grad_enabled(train):\n",
    "            for batch_idx, data in enumerate(d[phase]):\n",
    "\n",
    "                # Data and ground truth\n",
    "                images, masks = data\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                prob_mask = outputs.sigmoid()\n",
    "                loss = compare_loss(prob_mask, masks)\n",
    "                metric += loss\n",
    "                tot += len(data)\n",
    "\n",
    "                # Optimization of weights for training data\n",
    "                if phase == 'train':\n",
    "                    train_step += 1\n",
    "                    solver.zero_grad()\n",
    "                    loss.backward()\n",
    "                    solver.step()\n",
    "                    log['iterations'].append(loss.item())\n",
    "                elif phase == 'test':\n",
    "                    val_step += 1\n",
    "                    temp = outputs.detach().cpu().numpy()\n",
    "\n",
    "                tloss += loss.item()\n",
    "                c += 1\n",
    "\n",
    "        # Logging of train and test results\n",
    "        if phase == 'train':\n",
    "            log['epoch'].append(tloss/c)\n",
    "            log['train_acc'].append(metric / tot)\n",
    "            print('Epoch: ', epoch, 'Train loss: ',tloss/c, 'Metric: ', metric.cpu().item() / tot)\n",
    "            train_loss.append(tloss / c)\n",
    "\n",
    "        elif phase == 'test':\n",
    "            log['validation'].append(tloss / c)\n",
    "            log['val_acc'].append(metric / tot)\n",
    "            print('Epoch: ', epoch, 'Test loss:', tloss / c, 'Metric: ', metric.cpu().item() / tot)\n",
    "            test_loss.append(tloss / c)\n",
    "            accuracy = tloss / c #/ c\n",
    "            if (accuracy <= bestAccuracy):\n",
    "                print(\"New model saved!\")\n",
    "                bestAccuracy = accuracy\n",
    "                bestEpoch = epoch\n",
    "                save_best_model = os.path.join(log_path,'final_model.pth')\n",
    "                states = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': solver.state_dict(),\n",
    "                }\n",
    "                torch.save(states, save_best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "unet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
